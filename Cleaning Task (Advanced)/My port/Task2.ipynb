{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e86771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T16:10:29.998483Z",
     "start_time": "2024-04-12T16:10:23.209076Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import pycountry\n",
    "from fuzzywuzzy import fuzz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def standardize_column_names(filename, index_to_new_names):\n",
    "    # Load the workbook\n",
    "    wb = openpyxl.load_workbook(filename)\n",
    "    \n",
    "    # Iterate over each worksheet\n",
    "    for ws_name in wb.sheetnames:\n",
    "        sheet = wb[ws_name]\n",
    "        \n",
    "        # Iterate over the column indices specified in index_to_new_names\n",
    "        for index, new_name in index_to_new_names.items():\n",
    "            # Assuming 1-based indexing in Excel, so index - 1 corresponds to column number\n",
    "            column_letter = openpyxl.utils.get_column_letter(index)\n",
    "            cell = sheet[column_letter + '1']  # Access the cell in the first row of the specified column\n",
    "            cell.value = new_name  # Update the cell value\n",
    "    \n",
    "    # Save the modified workbook\n",
    "    wb.save(filename)\n",
    "    \n",
    "    \n",
    "\n",
    "df_countries = pd.read_excel('Countries IDs.xlsx')\n",
    "df_ports = pd.read_excel('Ports_ceties_codes_and_IDs.xlsx')\n",
    "df_note = {'Notes': []}\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Example usage\n",
    "filename = \"MyPoert AUG sheet1.xlsx\"  # Update with your filename\n",
    "index_to_new_names = {\n",
    "    1: \"Trip\",\n",
    "    2: \"Price\"# Example: Column index 1 will be renamed to \"Trip\"\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "standardize_column_names(filename, index_to_new_names)\n",
    "\n",
    "\n",
    "df_main = []\n",
    "sheet_names = []  # List to store sheet names\n",
    "\n",
    "# Load the workbook\n",
    "workbook = load_workbook('MyPoert AUG sheet1.xlsx')\n",
    "\n",
    "# Get the number of worksheets\n",
    "num_sheets = len(workbook.sheetnames)\n",
    "\n",
    "# Iterate over each sheet\n",
    "for sheet_no in range(num_sheets):\n",
    "    # Read data from the current sheet\n",
    "    df = pd.read_excel(\"MyPoert AUG sheet1.xlsx\", sheet_name=sheet_no).iloc[:, :2].dropna().reset_index(drop=True)\n",
    "    \n",
    "    # Add a new column with the sheet name\n",
    "    df['sheet_name'] = workbook.sheetnames[sheet_no]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_main.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df_master = pd.concat(df_main, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "for sheet in df_master['sheet_name'].unique():\n",
    "    match = None\n",
    "    max_similarity = 0\n",
    "    for country in df_countries['Country']:\n",
    "        similarity = fuzz.ratio(str(sheet), str(country)) / 100\n",
    "        if similarity >= 0.85 and similarity > max_similarity:\n",
    "            match = country\n",
    "            max_similarity = similarity\n",
    "\n",
    "    if match:\n",
    "        index = df_countries.index[df_countries['Country'] == match][0]\n",
    "        df_master.loc[df_master['sheet_name'] == sheet, 'sheet_name'] = df_countries.loc[index, 'ID']\n",
    "    else:\n",
    "        if sheet not in df_countries['Country'].values:\n",
    "            max_id = df_countries['ID'].max() + 1\n",
    "            new_row = pd.DataFrame({'Country': [sheet], 'ID': [max_id]})\n",
    "            df_countries = pd.concat([df_countries, new_row], ignore_index=True)\n",
    "            df_note['Notes'].append(f'New county its name is {sheet} is add with id {max_id} in Countries IDs.xlsx')\n",
    "            \n",
    "            \n",
    "            \n",
    "for i in range(len(df_master['Trip'])):\n",
    "    for j in range(len(df_countries['Country'])):\n",
    "        similarity = fuzz.ratio(str(df_master['sheet_name'][i]), str(df_countries['Country'][j])) / 100\n",
    "        if similarity >= 0.8:\n",
    "            df_master['sheet_name'][i] = df_countries['ID'][j]\n",
    "\n",
    "\n",
    "\n",
    "# Extract 'port_from' and 'port_to' using regex\n",
    "df_master[['port_from', 'port_to']] = df_master['Trip'].str.extract(r'FROM\\s+(.*?)\\s+TO\\s+(.*)', flags=re.IGNORECASE)\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Extract 'port_from' and 'port_to' using regex for NaN values in 'Trip' column\n",
    "additional_extraction = df_master[df_master['port_from'].isna()]['Trip'].str.extract(r'(?i)FROM\\s+(\\S+)\\s*TO\\s+(\\S+)', expand=True)\n",
    "# Replace NaN values in 'port_from' and 'port_to' with the extracted values\n",
    "df_master.loc[df_master['port_from'].isna(), ['port_from', 'port_to']] = additional_extraction.values\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "additional_extraction1 = df_master[df_master['port_from'].isna()]['Trip'].str.extract(r'(?i)FRM\\s+(\\S+)\\s*TO\\s+(\\S+)', expand=True)\n",
    "df_master.loc[df_master['port_from'].isna(), ['port_from', 'port_to']] = additional_extraction1.values\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Extract trip type using regex\n",
    "df_master['trip_type'] = df_master['Price'].str.extract(r'(ONE\\s*|ROUND)', flags=re.IGNORECASE)\n",
    "# Map extracted trip types to 'O' and 'R'\n",
    "df_master['trip_type'] = df_master['trip_type'].str.upper().str.replace('ONE', 'O').str.replace('ROUND', 'R')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_similar_ports_1_from(list1, list2):\n",
    "    similar_ports = {}\n",
    "    \n",
    "    for i, port1 in enumerate(list1):\n",
    "        max_similarity_score = 0\n",
    "        best_match = None\n",
    "        for port2 in list2:\n",
    "            similarity_score = fuzz.ratio(port1, port2)\n",
    "            if similarity_score > max_similarity_score:\n",
    "                max_similarity_score = similarity_score\n",
    "                best_match = port2\n",
    "        if max_similarity_score >= 80:  # You can adjust the threshold as needed\n",
    "            similar_ports[port1] = (best_match, max_similarity_score)\n",
    "            list1[i] = best_match\n",
    "    \n",
    "    \n",
    "    df_master['port_from'] = list1\n",
    "#     return similar_ports\n",
    "\n",
    "\n",
    "def find_similar_ports_1_to(list1, list2):\n",
    "    similar_ports = {}\n",
    "    \n",
    "    for i, port1 in enumerate(list1):\n",
    "        max_similarity_score = 0\n",
    "        best_match = None\n",
    "        for port2 in list2:\n",
    "            similarity_score = fuzz.ratio(port1, port2)\n",
    "            if similarity_score > max_similarity_score:\n",
    "                max_similarity_score = similarity_score\n",
    "                best_match = port2\n",
    "        if max_similarity_score >= 80:  # You can adjust the threshold as needed\n",
    "            similar_ports[port1] = (best_match, max_similarity_score)\n",
    "            list1[i] = best_match\n",
    "    \n",
    "    \n",
    "    df_master['port_to'] = list1\n",
    "#     return similar_ports\n",
    "\n",
    "\n",
    "\n",
    "find_similar_ports_1_to(list(df_master['port_to']),list(df_ports['Port Name']))\n",
    "find_similar_ports_1_from(list(df_master['port_from']),list(df_ports['Port Name']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold = 90  # Set the similarity threshold\n",
    "\n",
    "for i, port_to in enumerate(df_master['port_to']):\n",
    "    if isinstance(port_to, str):  # Check if the entry is a string\n",
    "        best_match = None\n",
    "        max_similarity_score = 0\n",
    "        for j, city in enumerate(df_ports['City']):\n",
    "            if isinstance(city, str):  # Check if the entry is a string\n",
    "                similarity_score = fuzz.ratio(port_to, city)\n",
    "                if similarity_score > max_similarity_score and similarity_score >= threshold and df_ports[df_ports['City'] == city].shape[0] == 1:\n",
    "                    max_similarity_score = similarity_score\n",
    "                    best_match = df_ports.iloc[j]['Port Name']\n",
    "                elif similarity_score > max_similarity_score and similarity_score >= threshold and df_ports[df_ports['City'] == city].shape[0] > 1:\n",
    "                    df_note['Notes'].append(f'{city} is city in port_to column in {i} row and I didn\\'t change it because there is more than port in this city')\n",
    "        if best_match:\n",
    "            df_master.at[i, 'port_to'] = best_match\n",
    "\n",
    "for i, port_from in enumerate(df_master['port_from']):\n",
    "    if isinstance(port_from, str):  # Check if the entry is a string\n",
    "        best_match = None\n",
    "        max_similarity_score = 0\n",
    "        for j, city in enumerate(df_ports['City']):\n",
    "            if isinstance(city, str):  # Check if the entry is a string\n",
    "                similarity_score = fuzz.ratio(port_from, city)\n",
    "                if similarity_score > max_similarity_score and similarity_score >= threshold and df_ports[df_ports['City'] == city].shape[0] == 1:\n",
    "                    max_similarity_score = similarity_score\n",
    "                    best_match = df_ports.iloc[j]['Port Name']\n",
    "                elif similarity_score > max_similarity_score and similarity_score >= threshold and df_ports[df_ports['City'] == city].shape[0] > 1:\n",
    "                    df_note['Notes'].append(f'{city} is city in port_from column in {i} row and I didn\\'t change it because there is more than port in this city')\n",
    "        if best_match:\n",
    "            df_master.at[i, 'port_from'] = best_match\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "df_master['port_from_id'] = None\n",
    "df_master['port_to_id'] = None\n",
    "df_master['port_from_code'] = None\n",
    "df_master['port_to_code'] = None\n",
    "\n",
    "df_master['publish_date'] = datetime.today().date()\n",
    "df_master['expir_date'] = datetime.today().date() + timedelta(days=33)\n",
    "\n",
    "for i in range(len(df_master['port_to'])):\n",
    "    for j in range(len(df_ports['Port Name'])):\n",
    "        if df_master['port_to'][i] == df_ports['Port Name'][j]:\n",
    "            df_master['port_to_id'][i] = df_ports['ID'][j]\n",
    "            df_master['port_to_code'][i] = df_ports['Code'][j]\n",
    "            \n",
    "        elif df_master['port_from'][i] == df_ports['Port Name'][j]:\n",
    "            df_master['port_from_id'][i] = df_ports['ID'][j]\n",
    "            df_master['port_from_code'][i] = df_ports['Code'][j]\n",
    "            \n",
    "            \n",
    "# Concatenate the columns with a hyphen and append trip_type\n",
    "df_master['url'] = df_master['port_from_code'] + '-' + df_master['port_to_code'] + '-' + df_master['trip_type']\n",
    "\n",
    "# If you want to convert the trip_type to lower case\n",
    "df_master['url'] = df_master['url'].str.lower()\n",
    "\n",
    "df_offer_temp = df_master[['port_from_id','port_to_id','trip_type','url','publish_date','expir_date']]\n",
    "df_master['extracted_numbers'] = df_master['Price'].apply(lambda x: int(re.findall(r'\\d+', x)[0]) if re.findall(r'\\d+', x) else None)\n",
    "df_master['extracted_numbers'] = df_master['extracted_numbers'].fillna(0)\n",
    "\n",
    "\n",
    "def transform_price(price):\n",
    "    arabic_digits = {'0': '۰', '1': '۱', '2': '۲', '3': '۳', '4': '٤', '5': '۵', '6': '٦', '7': '۷', '8': '۸', '9': '۹'}\n",
    "    arabic_number = ''.join(arabic_digits[digit] for digit in str(price) if digit.isdigit())\n",
    "    return {\"en\": str(price), \"ar\": arabic_number, \"gr\": str(price), \"it\": str(price), \"cz\": str(price), \"fr\": str(price), \"sk\": str(price)}\n",
    "\n",
    "# Apply the transformation to the 'Price' column\n",
    "df_master['transformed_price'] = df_master['extracted_numbers'].apply(lambda x: transform_price(x))\n",
    "\n",
    "df_offer_content = df_master[['url','sheet_name','transformed_price']]\n",
    "\n",
    "\n",
    "df_offer_temp.to_excel('offer_temp.xlsx',index= False)\n",
    "df_offer_content.to_excel('offer_content.xlsx',index= False)\n",
    "\n",
    "df_note = pd.DataFrame(df_note)\n",
    "df_note.to_excel('notes.xlsx',index= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119569b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
